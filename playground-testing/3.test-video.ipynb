{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d8e55d",
   "metadata": {},
   "source": [
    "# **Setup Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9acd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the project root so that relative paths in .env \n",
    "# (e.g., model weights, data directories) resolve correctly\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append('.')\n",
    "load_dotenv()\n",
    "\n",
    "from typing import Iterator\n",
    "import itertools\n",
    "from app.human_pose_estimator import (\n",
    "    HumanPoseEstimator2D,\n",
    "    HumanDetectorConfig,\n",
    "    PoseEstimatorConfig\n",
    ")\n",
    "from app.human_pose_estimator.types import RGBFrame\n",
    "from app.s3 import files_service\n",
    "from app.video import (\n",
    "    decode_from_minio_streaming,\n",
    "    encode_and_upload_to_minio_streaming,\n",
    "    render_annotated_frame,\n",
    "    stream_video_from_presigned_url\n",
    ")\n",
    "\n",
    "human_detector_config = HumanDetectorConfig()\n",
    "pose_estimator_config = PoseEstimatorConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MinIO â€” required by code that interacts with object storage\n",
    "!pixi run just minio-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f17ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_service.create_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc29627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After finishing your work, shut down MinIO to free resources\n",
    "# !pixi run just minio-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to 'assets/' so that files can be referenced directly \n",
    "# (e.g., 'test.png' instead of 'assets/test.png')\n",
    "%cd playground-testing/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4443352",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated_frame_generator(\n",
    "    frame_generator: Iterator[RGBFrame],\n",
    "    estimator: HumanPoseEstimator2D\n",
    ") -> Iterator[RGBFrame]:\n",
    "    \"\"\"\n",
    "    Transform a stream of raw video frames into annotated overlays.\n",
    "\n",
    "    This generator applies pose estimation to each input frame and renders\n",
    "    visual annotations (bounding box, keypoints, and skeleton) directly onto\n",
    "    the image. It is resolution-agnostic and processes frames sequentially,\n",
    "    making it suitable for memory-constrained streaming pipelines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame_generator : Iterator[RGBFrame]\n",
    "        Source of RGB video frames to annotate.\n",
    "    estimator : HumanPoseEstimator2D\n",
    "        Pose estimation model to apply on each frame.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    RGBFrame\n",
    "        Annotated frame with overlaid pose visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    for frame in frame_generator:\n",
    "        result = estimator(frame)\n",
    "        annotated = render_annotated_frame(\n",
    "            frame=frame,\n",
    "            keypoints=result.keypoints,\n",
    "            bounding_box=result.bbox\n",
    "        )\n",
    "        yield annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11af28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_visualization_end_to_end(\n",
    "    input_video_path: str,\n",
    "    output_video_path: str,\n",
    "    input_storage_key: str,\n",
    "    output_storage_key: str,\n",
    "    fps_target: float,\n",
    "    crf: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    End-to-end test for streaming video pose estimation and annotated video export.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_video_path : str\n",
    "        Local path to the source video file.\n",
    "    output_video_path : str\n",
    "        Local path where the annotated video will be saved.\n",
    "    input_storage_key : str\n",
    "        MinIO object key for the input video.\n",
    "    output_storage_key : str\n",
    "        MinIO object key for the output video.\n",
    "    fps_target : float\n",
    "        Target frame rate for decoding and encoding.\n",
    "    crf : int\n",
    "        Constant Rate Factor for H.264 encoding (lower = higher quality).\n",
    "        Must be in `[0, 51]`.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Upload input video to MinIO\n",
    "    with open(input_video_path, \"rb\") as f:\n",
    "        files_service.upload_fileobj(storage_key=input_storage_key, fileobj=f)\n",
    "\n",
    "    # 2. Initialize raw frame stream from MinIO\n",
    "    raw_frame_gen = decode_from_minio_streaming(\n",
    "        storage_key=input_storage_key,\n",
    "        expires=300,\n",
    "        fps_target=fps_target\n",
    "    )\n",
    "\n",
    "    # 3. Extract first frame to determine resolution\n",
    "    try:\n",
    "        first_frame = next(raw_frame_gen)\n",
    "    except StopIteration:\n",
    "        raise RuntimeError(\"Input video contains no frames\")\n",
    "\n",
    "    height, width = first_frame.shape[:2]\n",
    "\n",
    "    # 4. Reconstruct full frame stream including the first frame\n",
    "    full_raw_gen = itertools.chain([first_frame], raw_frame_gen)\n",
    "\n",
    "    # 5. Initialize pose estimator\n",
    "    human_pose_estimator = HumanPoseEstimator2D(\n",
    "        human_detector_config=human_detector_config,\n",
    "        pose_estimator_config=pose_estimator_config\n",
    "    )\n",
    "\n",
    "    # 6. Wrap in annotation generator\n",
    "    annotated_gen = annotated_frame_generator(\n",
    "        frame_generator=full_raw_gen,\n",
    "        estimator=human_pose_estimator\n",
    "    )\n",
    "\n",
    "    # 7. Encode and upload annotated video to MinIO\n",
    "    encode_and_upload_to_minio_streaming(\n",
    "        frame_generator=annotated_gen,\n",
    "        storage_key=output_storage_key,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        fps_target=fps_target,\n",
    "        crf=crf\n",
    "    )\n",
    "\n",
    "    # 8. Download resulting video for local inspection\n",
    "    presigned_url = files_service.generate_presigned_url(\n",
    "        storage_key=output_storage_key,\n",
    "        expires=300\n",
    "    )\n",
    "\n",
    "    # 9. Save resulting video\n",
    "    with open(output_video_path, \"wb\") as f:\n",
    "        for chunk in stream_video_from_presigned_url(presigned_url):\n",
    "            f.write(chunk)\n",
    "\n",
    "    print(f\"Successfully loaded video file '{input_video_path}', estimated pose, and saved resulting video to '{output_video_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_visualization_end_to_end(\n",
    "    input_video_path = \"test.mp4\",\n",
    "    output_video_path = \"3.annotated_test.mp4\",\n",
    "    input_storage_key = \"test3/input_video\",\n",
    "    output_storage_key = \"test3/output_video\",\n",
    "    fps_target = 5.0,\n",
    "    crf = 30\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
