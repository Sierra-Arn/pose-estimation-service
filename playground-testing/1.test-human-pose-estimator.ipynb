{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d8e55d",
   "metadata": {},
   "source": [
    "# **Setup Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60dfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the project root so that relative paths in .env \n",
    "# (e.g., model weights, data directories) resolve correctly\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append('.')\n",
    "load_dotenv()\n",
    "\n",
    "import cv2\n",
    "from app.human_pose_estimator import (\n",
    "    HumanPoseEstimator2D,\n",
    "    HumanDetectorConfig,\n",
    "    PoseEstimatorConfig\n",
    ")\n",
    "from app.video import render_annotated_frame\n",
    "\n",
    "human_detector_config = HumanDetectorConfig()\n",
    "pose_estimator_config = PoseEstimatorConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to 'assets/' so that files can be referenced directly \n",
    "# (e.g., 'test.png' instead of 'assets/test.png')\n",
    "%cd playground-testing/assets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d1c89",
   "metadata": {},
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_human_pose_estimator_2d_end_to_end(input_path: str, output_path: str) -> bool:\n",
    "\n",
    "    human_pose_estimator = HumanPoseEstimator2D(\n",
    "        human_detector_config=human_detector_config, \n",
    "        pose_estimator_config=pose_estimator_config\n",
    "    )\n",
    "    \n",
    "    frame = cv2.imread(input_path)\n",
    "    result = human_pose_estimator(frame)\n",
    "\n",
    "    overlay = render_annotated_frame(\n",
    "        frame=frame,\n",
    "        keypoints=result.keypoints,\n",
    "        bounding_box=result.bbox\n",
    "    )\n",
    "\n",
    "    success = cv2.imwrite(output_path, overlay)\n",
    "\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_human_pose_estimator_2d_end_to_end(\n",
    "    input_path = \"test.png\",\n",
    "    output_path = \"1.annotated_test.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
